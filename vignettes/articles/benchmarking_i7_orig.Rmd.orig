---
title: "Benchmarking i7"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      toc_levels: 2
    number_sections: true
    highlight: zenburn
    code_folding: show
    fig_caption: true
    df_print: paged 
---

<!-- This is a precomputing script. To run it, `knitr::knit("vignettes/articles/benchmarking_i7_orig.Rmd.orig", output = "vignettes/articles/benchmarking_i7.Rmd")` -->

<style>
p.caption {
  font-size: 0.6em;
  text-align: "center";
}
</style>

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.output = "70%"
) 
```

# DISCLAIMER

The present benchmark was conducted on `r Sys.Date()` on a Intel® Core™ i7-10510U (8-core CPU, Intel® UHD Graphics (CML GT2) GPU, 16GB RAM, Fedora 42). Results _will_ vary depending on the hardware. These benchmarks aim to provide a general idea of the performance differences between the `fio` package and other implementations but should not be considered definitive. The performance of the functions may also vary depending on the specific data used and the context in which they are applied.

# Introduction

This vignette presents a benchmarking analysis comparing the performance of functions from the `fio` package with equivalent base R functions and functions from other packages. The `fio` package provides a set of functions for input-output analysis, a method used in economics to analyze the interdependencies between different sectors of an economy.

Our benchmarking tests show that `fio` package functions are generally faster; reported memory figures come from `bench` and correspond to R-side allocations only. This improved timing performance can make a substantial difference in larger analyses, making the `fio` package a valuable tool for input-output analysis in R.

The tests were run on simulated square matrices, with dimensions ranging from 100x100 up to 2000x2000, and each test was repeated at least 20 times to account for variability. Please note that the results of this benchmarking analysis depend on the specific test datasets used and the hardware on which the algorithms were run. Therefore, the results should be interpreted in the context of these specific conditions.

# Technical coefficients matrix

The technical coefficients matrix calculation, a key and initial step in input-output analysis, was tested using the `compute_tech_coeff()` function from the `{fio}` package, equivalent functions from the `{leontief}` package, and a base R implementation. It consists of dividing each $a_{ij}$ element of the intermediate transactions matrix by the corresponding $x_j$ element of the total production vector^[Or equivalently, multiplying the intermediate transactions matrix by a diagonal matrix constructed from the total production vector.].

Note: the memory figures reported in the `bench` outputs correspond to allocations observed on the R side only; allocations performed inside native code (C++/Rust) are not captured by `bench::mem_alloc` and therefore these numbers may not reflect the full native memory usage of each implementation.

Results show that {fio} is generally faster than the other two implementations, especially for larger matrices (≥500x500). The timing results below illustrate relative speed differences across implementations.

```{r benchmark_i7_a, fig.cap="\\label{fig:benchmark_a} For larger matrices (≥500x500), {fio} is generally faster than alternatives."}
# set seed
set.seed(100)

# Base R function
tech_coeff_r <- function(intermediate_transactions, total_production) {
  tech_coeff_matrix <- intermediate_transactions %*% diag(1 / as.vector(total_production))
  return(tech_coeff_matrix)
}

# benchmark
benchmark_a <- bench::press(
  matrix_dim = c(100, 500, 1000, 2000),
  {
    intermediate_transactions <- matrix(
      as.double(sample(1:1000, matrix_dim^2, replace = TRUE)),
      nrow = matrix_dim,
      ncol = matrix_dim
    )
    total_production <- matrix(
      as.double(sample(4000000:6000000, matrix_dim, replace = TRUE)),
      nrow = 1,
      ncol = matrix_dim
    )
    iom_fio <- fio::iom$new("iom", intermediate_transactions, total_production)
    bench::mark(
      fio = fio:::compute_tech_coeff(intermediate_transactions, total_production),
      `Base R` = tech_coeff_r(intermediate_transactions, total_production),
      leontief = leontief::input_requirement(intermediate_transactions, total_production),
      iterations = 100
    )
  }
)
subset(benchmark_a, select = c("expression", "matrix_dim", "min", "median", "mem_alloc", "gc/sec", "n_gc", "total_time"))

# plot
ggplot2::autoplot(benchmark_a)
```

<div class="figure" style="text-align: center">
<img src="figure/benchmark_i7_a-1.png" alt="\\label{fig:benchmark_a} For larger matrices (≥500x500), {fio} is generally faster than alternatives."  />
<p class="caption">\\label{fig:benchmark_a} For larger matrices (≥500x500), {fio} is generally faster than alternatives. Note: reported memory figures are R-side only and may not include native (C++/Rust) allocations.</p>
</div>

# Leontief inverse matrix

The Leontief matrix ($L$) is obtained by subtracting the technical coefficients matrix ($A$) from the identity matrix ($I$); therefore, it has no null rows or columns. This allows for solving the linear system $L \times L^{-1} = I$ through LU decomposition, which is a more efficient method than direct inverse matrix calculation.

Results show that for larger matrices, `{fio}` is slightly slower than the alternatives, but timing results indicate competitive performance. As above, reported memory numbers are R-side only and may not include native allocations.

```{r benchmark_i7_b, fig.cap="\\label{fig:benchmark_b} Faster on the R side; reported memory figures are R-side only (see note)."}
# base R function
leontief_inverse_r <- function(technical_coefficients_matrix) {
  dim <- nrow(technical_coefficients_matrix)
  leontief_inverse_matrix <- solve(diag(dim) - technical_coefficients_matrix)
  return(leontief_inverse_matrix)
}

# benchmark
benchmark_b <- bench::press(
  matrix_dim = c(100, 500, 1000, 2000),
  {
    intermediate_transactions <- matrix(
      as.double(sample(1:1000, matrix_dim^2, replace = TRUE)),
      nrow = matrix_dim,
      ncol = matrix_dim
    )
    total_production <- matrix(
      as.double(sample(4000000:6000000, matrix_dim, replace = TRUE)),
      nrow = 1,
      ncol = matrix_dim
    )
    iom_fio <- fio::iom$new("iom", intermediate_transactions, total_production)
    iom_fio$compute_tech_coeff()
    technical_coefficients_matrix <- iom_fio$technical_coefficients_matrix
    bench::mark(
      fio = fio:::compute_leontief_inverse(technical_coefficients_matrix),
      `Base R` = leontief_inverse_r(technical_coefficients_matrix),
      leontief = leontief::leontief_inverse(technical_coefficients_matrix),
      iterations = 100,
      check = FALSE
    )
  }
)
subset(benchmark_b, select = c("expression", "matrix_dim", "min", "median", "mem_alloc", "gc/sec", "n_gc", "total_time"))

# plot
ggplot2::autoplot(benchmark_b)
```

<div class="figure" style="text-align: center">
<img src="figure/benchmark_i7_b-1.png" alt="\\label{fig:benchmark_b} Faster on the R side; reported memory figures are R-side only (see note)."  />
<p class="caption">\\label{fig:benchmark_b} Faster on the R side; reported memory figures are R-side only (see note).</p>
</div>

# Sensitivity of dispersion coefficients of variation

To evaluate the performance of linkage-based functions, we benchmarked the sensitivity of dispersion coefficients of variation.

Results shows that {fio} is substantially faster and more memory-efficient than {leontief} across all tested dimensions. Compared to Base R, {fio} is faster for matrices 1000x1000 and larger, while memory usage remains comparable.

```{r benchmark_i7_c, fig.cap="\\label{fig:benchmark_c} Faster on the R side; reported memory figures are R-side only (see note)."}
# base R function
sensitivity_r <- function(B) {
  n <- nrow(B)
  SL = rowSums(B)
  ML = SL / n
  (((1 / (n - 1)) * (colSums((B - ML) ** 2))) ** 0.5) / ML
}

# benchmark
benchmark_c <- bench::press(
  matrix_dim = c(100, 500, 1000, 2000),
  {
    intermediate_transactions <- matrix(
      as.double(sample(1:1000, matrix_dim^2, replace = TRUE)),
      nrow = matrix_dim,
      ncol = matrix_dim
    )
    total_production <- matrix(
      as.double(sample(4000000:6000000, matrix_dim, replace = TRUE)),
      nrow = 1,
      ncol = matrix_dim
    )
    iom_fio <- fio::iom$new("iom", intermediate_transactions, total_production)
    iom_fio$compute_tech_coeff()$compute_leontief_inverse()
    leontief_inverse_matrix <- iom_fio$leontief_inverse_matrix
    bench::mark(
      fio = fio:::compute_sensitivity_dispersion_cv(leontief_inverse_matrix),
      `Base R` = sensitivity_r(leontief_inverse_matrix),
      leontief = leontief::sensitivity_dispersion_cv(leontief_inverse_matrix),
      iterations = 100,
      check = FALSE
    )
  }
)
subset(benchmark_c, select = c("expression", "matrix_dim", "min", "median", "mem_alloc", "gc/sec", "n_gc", "total_time"))
ggplot2::autoplot(benchmark_c)
```

<div class="figure" style="text-align: center">
<img src="figure/benchmark_i7_c-1.png" alt="\\label{fig:benchmark_c} Faster on the R side; reported memory figures are R-side only (see note)."  />
<p class="caption">\\label{fig:benchmark_c} Faster on the R side; reported memory figures are R-side only (see note).</p>
</div>

# Field of influence

Since computing the field of influence involves calculating the Leontief inverse matrix for each element of the technical coefficients matrix after an increment, it can be demanding for high-dimensional matrices. Here, we benchmark the base R function and `{fio}`, as there is no similar function in `{leontief}`. For brevity, we limited the matrix dimensions to 100x100 and the number of repetitions to 10.

Results shows that {fio} is faster than the base R implementation; the `bench` summaries report much smaller R-side allocations for `fio` in these tests. For the 200x200 matrix the `bench` output shows R-side allocations of 625KB for `fio` and 83.73GB for the base R implementation, but these figures correspond to memory observed on the R heap only and do not include allocations performed inside native code (C++/Rust).

```{r benchmark_i7_d, fig.cap="\\label{fig:benchmark_d} Superior timing on the R side; reported memory figures are R-side only (see note)."}
# base R function
field_influence_r <- function(A, B, ee = 0.001) {
  n = nrow(A)
  I = diag(n)
  E = matrix(0, ncol = n, nrow = n)
  SI = matrix(0, ncol = n, nrow = n)
  for (i in 1:n) {
    for (j in 1:n) {
      E[i, j] = ee
      AE = A + E
      BE = solve(I - AE)
      FE = (BE - B) / ee
      FEq = FE * FE
      S = sum(FEq)
      SI[i, j] = S
      E[i, j] = 0
    }
  }
  return(SI) # Added return statement
}

# benchmark
benchmark_d <- bench::press(
  matrix_dim = c(30, 60, 100, 200),
  {
    intermediate_transactions <- matrix(
      as.double(sample(1:1000, matrix_dim^2, replace = TRUE)),
      nrow = matrix_dim,
      ncol = matrix_dim
    )
    total_production <- matrix(
      as.double(sample(4000000:6000000, matrix_dim, replace = TRUE)),
      nrow = 1,
      ncol = matrix_dim
    )
    iom_fio_reduced <- fio::iom$new(
      "iom_reduced",
      intermediate_transactions,
      total_production
    )$compute_tech_coeff()$compute_leontief_inverse()
    bench::mark(
      fio = fio:::compute_field_influence(
        iom_fio_reduced$technical_coefficients_matrix,
        iom_fio_reduced$leontief_inverse_matrix,
        0.001
      ),
      `Base R` = field_influence_r(
        iom_fio_reduced$technical_coefficients_matrix,
        iom_fio_reduced$leontief_inverse_matrix
      ),
      iterations = 20,
      check = FALSE
    )
  }
)
subset(benchmark_d, select = c("expression", "matrix_dim", "min", "median", "mem_alloc", "gc/sec", "n_gc", "total_time"))
ggplot2::autoplot(benchmark_d)
```

<div class="figure" style="text-align: center">
<img src="figure/benchmark_i7_d-1.png" alt="\\label{fig:benchmark_d} Superior timing on the R side; reported memory figures are R-side only (see note)."  />
<p class="caption">\\label{fig:benchmark_d} Superior timing on the R side; reported memory figures are R-side only (see note).</p>
</div>